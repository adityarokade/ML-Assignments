{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The definition of a feature is a part of the face, a quality, a special attraction, article or a major film showing in the theatre. An example of feature is a nose. An example of feature is freckles. An example of feature is a guest speaker at an event. An example of feature is a cover story in a magazine.\n"
     ]
    }
   ],
   "source": [
    "#1. What exactly is a feature? Give an example to illustrate your point.\n",
    "\n",
    "print(\"The definition of a feature is a part of the face, a quality, a special attraction, article or a major film showing in the theatre. An example of feature is a nose. An example of feature is freckles. An example of feature is a guest speaker at an event. An example of feature is a cover story in a magazine.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Selection is the method of reducing the input variable to your model by using only relevant data and getting rid of noise in data. It is the process of automatically choosing relevant features for your machine learning model based on the type of problem you are trying to solve.\n"
     ]
    }
   ],
   "source": [
    "#2. What are the various circumstances in which feature construction is required?\n",
    "\n",
    "print(\"Feature Selection is the method of reducing the input variable to your model by using only relevant data and getting rid of noise in data. It is the process of automatically choosing relevant features for your machine learning model based on the type of problem you are trying to solve.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When we have a feature where variables are just names and there is no order or rank to this variable's feature. For example: City of person lives in, Gender of person, Marital Status, etc… In the above example, We do not have any order or rank, or sequence.\n"
     ]
    }
   ],
   "source": [
    "#3. Describe how nominal variables are encoded.\n",
    "\n",
    "print(\"When we have a feature where variables are just names and there is no order or rank to this variable's feature. For example: City of person lives in, Gender of person, Marital Status, etc… In the above example, We do not have any order or rank, or sequence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At first thought, converting numeric data to categorical data seems like an easy problem. One simple approach would be to divide the raw source data into equal intervals. For example, for the data in the demo and Figure 2, the range is 78.0 - 60.0 = 18.0.\n"
     ]
    }
   ],
   "source": [
    "#4. Describe how numeric features are converted to categorical features.\n",
    "\n",
    "print(\"At first thought, converting numeric data to categorical data seems like an easy problem. One simple approach would be to divide the raw source data into equal intervals. For example, for the data in the demo and Figure 2, the range is 78.0 - 60.0 = 18.0.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In wrapper methods, the feature selection process is based on a specific machine learning algorithm that we are trying to fit on a given dataset. It follows a greedy search approach by evaluating all the possible combinations of features against the evaluation criterion.\n",
      "The two main disadvantages of these methods are: The increasing overfitting risk when the number of observations is insufficient. The significant computation time when the number of variables is large.\n"
     ]
    }
   ],
   "source": [
    "#5. Describe the feature selection wrapper approach. State the advantages and disadvantages of this approach?\n",
    "\n",
    "print(\"In wrapper methods, the feature selection process is based on a specific machine learning algorithm that we are trying to fit on a given dataset. It follows a greedy search approach by evaluating all the possible combinations of features against the evaluation criterion.\")\n",
    "\n",
    "\n",
    "print(\"The two main disadvantages of these methods are: The increasing overfitting risk when the number of observations is insufficient. The significant computation time when the number of variables is large.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Selection is the method of reducing the input variable to your model by using only relevant data and getting rid of noise in data. It is the process of automatically choosing relevant features for your machine learning model based on the type of problem you are trying to solve\n"
     ]
    }
   ],
   "source": [
    "#6. When is a feature considered irrelevant? What can be said to quantify it?\n",
    "\n",
    "print(\"Feature Selection is the method of reducing the input variable to your model by using only relevant data and getting rid of noise in data. It is the process of automatically choosing relevant features for your machine learning model based on the type of problem you are trying to solve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For example, if two features {X1, X2} are highly correlated, then the two features become redundant features since they have same information in terms of correlation measure. In other words, the correlation measure provides statistical association between any given a pair of features.\n"
     ]
    }
   ],
   "source": [
    "#7. When is a function considered redundant? What criteria are used to identify features that could be redundant?\n",
    "\n",
    "print(\"For example, if two features {X1, X2} are highly correlated, then the two features become redundant features since they have same information in terms of correlation measure. In other words, the correlation measure provides statistical association between any given a pair of features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perhaps four of the most commonly used distance measures in machine learning are as follows: Hamming Distance. Euclidean Distance. Manhattan Distance.\n"
     ]
    }
   ],
   "source": [
    "#8. What are the various distance measurements used to determine feature similarity?\n",
    "\n",
    "print(\"Perhaps four of the most commonly used distance measures in machine learning are as follows: Hamming Distance. Euclidean Distance. Manhattan Distance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distance is the shortest path between source and destination which is a straight line as shown in Figure 1.3. but Manhattan distance is sum of all the real distances between source(s) and destination(d) and each distance are always the straight lines as shown in\n"
     ]
    }
   ],
   "source": [
    "#9. State difference between Euclidean and Manhattan distances?\n",
    "\n",
    "print(\"Euclidean distance is the shortest path between source and destination which is a straight line as shown in Figure 1.3. but Manhattan distance is sum of all the real distances between source(s) and destination(d) and each distance are always the straight lines as shown in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction is the process of converting the raw data into (usually) some other data type, which the algorithm works with. Feature selection is the process of selecting specific features, from a features pool.\n"
     ]
    }
   ],
   "source": [
    "#10. Distinguish between feature transformation and feature selection.\n",
    "\n",
    "\n",
    "print(\"Feature extraction is the process of converting the raw data into (usually) some other data type, which the algorithm works with. Feature selection is the process of selecting specific features, from a features pool.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
