{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. A set of one-dimensional data points is given to you: 5, 10, 15, 20, 25, 30, 35. Assume that k = 2 and that the first set of random centroid is 15, 32, and that the second set is 12, 30.\n",
    "#a) Using the k-means method, create two clusters for each set of centroid described above.\n",
    "#b) For each set of centroid values, calculate the SSE.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Association rules for market basket analysis\n",
      "In market basket analysis, association rules are used to predict the likelihood of products being purchased together. Association rules count the frequency of items that occur together, seeking to find associations that occur far more often than expected.\n"
     ]
    }
   ],
   "source": [
    "#2. Describe how the Market Basket Research makes use of association analysis concepts.\n",
    "\n",
    "print(\"\"\"Association rules for market basket analysis\n",
    "In market basket analysis, association rules are used to predict the likelihood of products being purchased together. Association rules count the frequency of items that occur together, seeking to find associations that occur far more often than expected.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: list of items purchased by customers, details of website which are frequently visited etc. This algorithm was introduced by Agrawal and Srikant in 1994. Subset of frequent itemset are frequent itemset.\n",
      "...\n",
      "All the possible association rules can be,\n",
      "I1 -> I2.\n",
      "I2 -> I3.\n",
      "I2 -> I5.\n",
      "I2 -> I1.\n",
      "I3 -> I2.\n",
      "I5 -> I2.\n"
     ]
    }
   ],
   "source": [
    "#3. Give an example of the Apriori algorithm for learning association rules.\n",
    "\n",
    "\n",
    "print(\"\"\"Example: list of items purchased by customers, details of website which are frequently visited etc. This algorithm was introduced by Agrawal and Srikant in 1994. Subset of frequent itemset are frequent itemset.\n",
    "...\n",
    "All the possible association rules can be,\n",
    "I1 -> I2.\n",
    "I2 -> I3.\n",
    "I2 -> I5.\n",
    "I2 -> I1.\n",
    "I3 -> I2.\n",
    "I5 -> I2.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For most common hierarchical clustering software, the default distance measure is the Euclidean distance. This is the square root of the sum of the square differences. However, for gene expression, correlation distance is often used.\n"
     ]
    }
   ],
   "source": [
    "#4. In hierarchical clustering, how is the distance between clusters measured? Explain how this metric is used to decide when to end the iteration.\n",
    "\n",
    "\n",
    "print(\"For most common hierarchical clustering software, the default distance measure is the Euclidean distance. This is the square root of the sum of the square differences. However, for gene expression, correlation distance is often used.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How does the K-Means Algorithm Work?\n",
      "Step-1: Select the number K to decide the number of clusters.\n",
      "Step-2: Select random K points or centroids. ...\n",
      "Step-3: Assign each data point to their closest centroid, which will form the predefined K clusters.\n",
      "Step-4: Calculate the variance and place a new centroid of each cluster.\n"
     ]
    }
   ],
   "source": [
    "#5. In the k-means algorithm, how do you recompute the cluster centroids?\n",
    "\n",
    "\n",
    "print(\"\"\"How does the K-Means Algorithm Work?\n",
    "Step-1: Select the number K to decide the number of clusters.\n",
    "Step-2: Select random K points or centroids. ...\n",
    "Step-3: Assign each data point to their closest centroid, which will form the predefined K clusters.\n",
    "Step-4: Calculate the variance and place a new centroid of each cluster.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probably the most well known method, the elbow method, in which the sum of squares at each number of clusters is calculated and graphed, and the user looks for a change of slope from steep to shallow (an elbow) to determine the optimal number of clusters.\n"
     ]
    }
   ],
   "source": [
    "#6. At the start of the clustering exercise, discuss one method for determining the required number of clusters.\n",
    "\n",
    "\n",
    "print(\"Probably the most well known method, the elbow method, in which the sum of squares at each number of clusters is calculated and graphed, and the user looks for a change of slope from steep to shallow (an elbow) to determine the optimal number of clusters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) If variables are huge, then K-Means most of the times computationally faster than hierarchical clustering, if we keep k smalls. 2) K-Means produce tighter clusters than hierarchical clustering, especially if the clusters are globular. K-Means Disadvantages : 1) Difficult to predict K-Value.\n"
     ]
    }
   ],
   "source": [
    "#7. Discuss the k-means algorithm's advantages and disadvantages.\n",
    "\n",
    "\n",
    "print(\"1) If variables are huge, then K-Means most of the times computationally faster than hierarchical clustering, if we keep k smalls. 2) K-Means produce tighter clusters than hierarchical clustering, especially if the clusters are globular. K-Means Disadvantages : 1) Difficult to predict K-Value.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Draw a diagram to demonstrate the principle of clustering'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Code efficiency can be calculated by using the below two formulas:\n",
      "Test Efficiency = (Total number of bugs found in unit+integration+system) / (total number of defects found in unit+integration+system+User acceptance testing)\n",
      "Testing Efficiency = Number of bugs resolved/ number of bugs raised *100.\n"
     ]
    }
   ],
   "source": [
    "#10. In a software project, the team is attempting to determine if software flaws discovered during testing are identical. Based on the text analytics of the defect details, they decided to build 5 clusters of related defects. Any new defect formed after the 5 clusters of defects have been identified must be listed as one of the forms identified by clustering. A simple diagram can be used to explain this process. Assume you have 20 defect data points that are clustered into 5 clusters and you used the k-means algorithm.\n",
    "\n",
    "print(\"\"\"Answer: Code efficiency can be calculated by using the below two formulas:\n",
    "Test Efficiency = (Total number of bugs found in unit+integration+system) / (total number of defects found in unit+integration+system+User acceptance testing)\n",
    "Testing Efficiency = Number of bugs resolved/ number of bugs raised *100.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
